{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3Sqaw8fkh-B"
   },
   "source": [
    "<p><font size=\"6\" color='grey'> <b>\n",
    "Machine Learning\n",
    "</b></font> </br></p>\n",
    "<p><font size=\"5\" color='grey'> <b>\n",
    "Snippets\n",
    "</b></font> </br></p>\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cO3WizxxG80I"
   },
   "source": [
    "# 1 | Understand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nhp-ceAziZO3"
   },
   "source": [
    "# 1.1 | Read DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFk4S8G2t6sG"
   },
   "source": [
    "# 1.1a | Read OpenML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgKvATPf89H7"
   },
   "outputs": [],
   "source": [
    "data_id = 43406\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "df = fetch_openml(parser='auto', target_column='default-target', data_id=data_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QkUloVu4-HMi"
   },
   "outputs": [],
   "source": [
    "data = df.data.copy()\n",
    "target = df.target.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GY9_DS0iMGo"
   },
   "source": [
    "# 1.1b | Read Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSyjUT_qiQMT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ralf-42/ml-kurs/main/02%20data/BodyPerformance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wr5QN5u2iUWy"
   },
   "outputs": [],
   "source": [
    "label = 'class'\n",
    "features = [n for n in df.columns if n != label]\n",
    "\n",
    "target = df[label].copy()\n",
    "data = df[features].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQ68SwBd9OyW"
   },
   "source": [
    "# 1.1c | Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lXlnmcMyG9DU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "filename = ''\n",
    "df = pd.read_csv(filename, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nyVafehSiLTE"
   },
   "outputs": [],
   "source": [
    "label = 'class'\n",
    "features = [n for n in df.columns if n != label]\n",
    "\n",
    "target = df[label].copy()\n",
    "data = df[features].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxcV51QtilCo"
   },
   "source": [
    "# 1.1d | Read Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2TmhRM1iqB-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "filename = ''\n",
    "df = pd.read_excel(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7XU0dhDriz3d"
   },
   "outputs": [],
   "source": [
    "label = 'class'\n",
    "features = [n for n in df.columns if n != label]\n",
    "\n",
    "target = df[label].copy()\n",
    "data = df[features].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cWkGhG-i03_"
   },
   "source": [
    "# 1.1e | Read arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1yw1w8HMlTui"
   },
   "outputs": [],
   "source": [
    "!pip install -q liac-arff\n",
    "import arff\n",
    "import pandas as pd\n",
    "\n",
    "def read_arff_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data_dict = arff.load(f)\n",
    "    data = data_dict['data']\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = [attr[0] for attr in data_dict['attributes']]\n",
    "    return df\n",
    "\n",
    "file_path = '/content/phpMYEkMl.arff'\n",
    "df = read_arff_file(file_path)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JXf146TzXdh"
   },
   "source": [
    "# 1.2 | EDA - Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J7JmQY7_zZDJ"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F12P_Eoj_zYZ"
   },
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0UepWqRX_0-W"
   },
   "outputs": [],
   "source": [
    "data.describe(include=object).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ldxsQOKJ_27w"
   },
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JWfoP5Wd_6jj"
   },
   "outputs": [],
   "source": [
    "col_name = ''\n",
    "data.groupby(col_name).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TmJ7Vs83_8P7"
   },
   "outputs": [],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJm4XH32_-4W"
   },
   "outputs": [],
   "source": [
    "# _ = data.hist(figsize=(15,15))\n",
    "# _ = data.plot.scatter(x='length', y='width', c='DarkBlue')\n",
    "# _ = pd.scatter_matrix(data[features])\n",
    "# _ = pd.plotting.scatter_matrix(data, alpha=0.2, figsize=[15,15], c='darkblue')\n",
    "# _ = data.boxplot(column=['age', 'pclass'], figsize=[10,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbBQSUPnBPFD"
   },
   "source": [
    "# 1.3 | EDA - Pandas Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ogiIxg4eGGW"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  from pandas_profiling import ProfileReport\n",
    "except:\n",
    "  !pip install -q pandas-profiling\n",
    "  from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-fHLR-NyeM0Y"
   },
   "outputs": [],
   "source": [
    "report = ProfileReport(data)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R49wX8AcgdPJ"
   },
   "outputs": [],
   "source": [
    "#  report.to_file(\"report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9VeDtH-BV-W"
   },
   "source": [
    "# 1.4 | EDA - SweetViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MxTrVl4PgupP"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import sweetviz as sv\n",
    "except:\n",
    "  !pip install -q sweetviz\n",
    "  import sweetviz as sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zMM6EwtBg6yx"
   },
   "outputs": [],
   "source": [
    "report = sv.analyze(data)\n",
    "report.show_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4CFI0uyHkuIj"
   },
   "outputs": [],
   "source": [
    "# comparison_report = sv.compare([data_train,'Train'], [data_test,'Test'], target_feat='class')\n",
    "# comparison_report.show_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ogfC022rkMNz"
   },
   "outputs": [],
   "source": [
    "# report.show_html('report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0kZq6iTtvsp"
   },
   "source": [
    "# 1.5 | EDA - DataPrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V66-VrV0HPgI"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from dataprep.eda import create_report, plot, plot_correlation, plot_missing, plot_diff\n",
    "    from dataprep.clean.clean_headers import clean_headers\n",
    "except:\n",
    "    !pip install -q dataprep\n",
    "    from dataprep.eda import create_report, plot, plot_correlation, plot_missing, plot_diff\n",
    "    from dataprep.clean.clean_headers import clean_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fzrrkxUr89G"
   },
   "outputs": [],
   "source": [
    "create_report(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1hLVIPY_sBFi"
   },
   "outputs": [],
   "source": [
    "# clean_headers(data, case='camel', replace={'XXX': 'YYY'})     # Cleaning the header-names / feature-names\n",
    "# plot(data)                  # Histogram for all feartures\n",
    "# plot_missing(data)          # missing data\n",
    "# plot_missing(data, \"...\")   # Impact of missing data\n",
    "# plot_correlation(data)      # correlation\n",
    "# plot(data, \"...\", \"...\")    # Relationship between two features\n",
    "# plot(data, \"...\")           # Single feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhfT9PdGf4GX"
   },
   "source": [
    "# 1.6 | EDA - Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i9MTsgX-ly-N"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.subplots as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hlJ0nA6wLUys"
   },
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "title_ = 'Titel-Text'\n",
    "px.box(data[['col1', 'col2']], title=title_, width=600, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYD-v8e2stlN"
   },
   "outputs": [],
   "source": [
    "# 3 Boxplots\n",
    "title_ = 'col1'\n",
    "box1 = px.box(data['col1'], title=title_, width=600, height=600)\n",
    "\n",
    "title_ = 'col2'\n",
    "box2 = px.box(data['col2'], title=title_, width=600, height=600)\n",
    "\n",
    "title_ = 'col3'\n",
    "box3 = px.box(data['col2], title=title_, width=600, height=600)\n",
    "\n",
    "fig = sp.make_subplots(rows=1, cols=3, subplot_titles=('col1', 'col2', 'col3'))\n",
    "\n",
    "for trace in box1.data:\n",
    "    fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "for trace in box2.data:\n",
    "    fig.add_trace(trace, row=1, col=2)\n",
    "\n",
    "for trace in box3.data:\n",
    "    fig.add_trace(trace, row=1, col=3)\n",
    "\n",
    "# Layout anpassen\n",
    "fig.update_layout(width=1000, height=500, title_text='Box-Plots')\n",
    "\n",
    "# Plot anzeigen\n",
    "fig.show()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfYSvLZA6PWa"
   },
   "outputs": [],
   "source": [
    "# Scattergramm\n",
    "title_ = 'Titel-Text'\n",
    "px.scatter(data, x='col1', y='col2', color='target', labels={\"col1\": \"xxxx\",\"col2\": \"yyyy\"}, title=title_, width=1200, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-mS62mYYLIMo"
   },
   "outputs": [],
   "source": [
    "# Scatter Matrix\n",
    "px.scatter_matrix(data, dimensions=data.columns, opacity=1)\n",
    "# px.scatter_matrix(data, dimensions=data.columns, opacity=1, color=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJ04w6l66doD"
   },
   "outputs": [],
   "source": [
    "# Linie\n",
    "px.line(data, x= 'col1', y='col2', width=800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aodL9sOpGyM0"
   },
   "source": [
    "# 1.7 | EDA - PyGWalker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fBlVeanhG5AW"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import pygwalker as pyg\n",
    "except:\n",
    "  !pip install -q pygwalker\n",
    "  import pygwalker as pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LnSurzj4HL06"
   },
   "outputs": [],
   "source": [
    "pyg.walk(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcfPgWTMONq4"
   },
   "source": [
    "# 1.8 | EDA - Yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dhc7KmkhOS3H"
   },
   "outputs": [],
   "source": [
    "from yellowbrick.target import class_balance\n",
    "visualizer = class_balance(target, labels=[\"A\", \"B\", \"C\", \"D\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65K6EoL7HHly"
   },
   "source": [
    "# 2 | Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-3PtOrx0hhY"
   },
   "source": [
    "# 2.1 | Datentypen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUEEfjP3mp9A"
   },
   "source": [
    "# 2.1.1 | Datentyp ermitteln\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UQIl_hhfkjTJ"
   },
   "outputs": [],
   "source": [
    "all_col = data.columns\n",
    "num_col = data.select_dtypes(include='number').columns\n",
    "cat_col = data.select_dtypes(exclude='number').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTTTfWUgmqFU"
   },
   "source": [
    "# 2.1.2 | Datentyp ändern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Kd6MG8SjOo3"
   },
   "outputs": [],
   "source": [
    "df['column_name'] = df['column_name'].astype(int)\n",
    "df['column_name'] = df['column_name'].astype(float)\n",
    "df['column_name'] = df['column_name'].astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_r6jjOnY0liS"
   },
   "source": [
    "# 2.2 | Duplikate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxQuQ_Yr0qf-"
   },
   "source": [
    "# 2.2.1 | Duplikate ermitteln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rBjZ1Im40uKF"
   },
   "outputs": [],
   "source": [
    "duplicates = data[data.duplicated()]\n",
    "print(\"Anzahl Duplicate: \", len(duplicates))\n",
    "# print(\"Duplizierte Einträge:\")\n",
    "# print(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-s4qTMq1InQ"
   },
   "source": [
    "# 2.2.2 | Duplikate löschen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dz9ho2q61BIJ"
   },
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)  # Parameter: subset - column name(s) for duplicate identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwuxgST8Pmfc"
   },
   "source": [
    "# 2.3 | Featue löschen / umbenennen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJ8hRzn6aIP5"
   },
   "source": [
    "# 2.3.1 | Feature löschen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BUlt-epItXhL"
   },
   "outputs": [],
   "source": [
    "# Löschen von Spalten\n",
    "data.drop(['col1', 'col2'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_TAfRLCZheu"
   },
   "source": [
    "# 2.3.2 | Feature umbenennen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TFjQFHLm8TOl"
   },
   "outputs": [],
   "source": [
    "data.rename(columns = {'old_col1':'new_col1', 'old_col2':'new_col2'}, inplace = True)\n",
    "data.columns = ['new1', 'new2', 'new3', 'new4']\n",
    "data.columns = data.columns.str.replace('old_char', 'new_char')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCb4mTGfmpzo"
   },
   "source": [
    "# 2.4 | Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgKcm9_HTmsk"
   },
   "source": [
    "# 2.4.1 | Prüfen auf Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQM8rfNpsYHw"
   },
   "outputs": [],
   "source": [
    "# --- Berechne die Anzahl der fehlenden Werte pro Spalte\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RICK4opXTrdO"
   },
   "source": [
    "# 2.4.2 | Python Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pNTBjL22ssN-"
   },
   "outputs": [],
   "source": [
    "# --- Entferne Zeilen mit fehlenden Daten\n",
    "data.dropna(inplace=True)\n",
    "# --- Ersetze durch Mittelwert, Median, Mode\n",
    "data['A'].replace([numpy.nan], data['A'].mean(), inplace=True)\n",
    "data['B'].replace([numpy.nan], data['B'].median(), inplace=True)\n",
    "data['C'].replace([numpy.nan], data['C'].mode()[0], inplace=True)\n",
    "# --- Ersetze durch Vorgänger/Nachfolger\n",
    "data.fillna(method='ffill', inplace=True)\n",
    "data.fillna(method='bfill', inplace=True)\n",
    "# --- Ersetze durch Konstante -999\n",
    "data.fillna(value=-999, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cb9C30MjTwx3"
   },
   "source": [
    "# 2.4.3 | SciKit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_TqtBKRRDnP7"
   },
   "outputs": [],
   "source": [
    "mv = data.isnull().sum()\n",
    "mv_col = list(mv[mv > 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OV5X4M7mFFCy"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "missing_data = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "data[mv_col] = pd.DataFrame(missing_data.fit_transform(data[mv_col]), columns=mv_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPdhVA_6mxpc"
   },
   "source": [
    "# 2.5 | Outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzYXteA2FISC"
   },
   "source": [
    "# 2.5.1 | Outlier via Standardabweichung\n",
    "Mehr als 3 Standardabweichungen vom Mittelwert entfernt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lE1ry6tiFM6E"
   },
   "outputs": [],
   "source": [
    "# Entferne Datenpunkte, die mehr als 3 Standardabweichungen vom Mittelwert entfernt sind\n",
    "data = data[(data - data.mean()) / data.std() < 3].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9sK8P7RLPyU"
   },
   "source": [
    "# 2.5.2 |  Outlier via 1.5 IQR (Boxplot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T25lfy1qK4qW"
   },
   "outputs": [],
   "source": [
    "# calculate the first and third quartiles (Q1 and Q3)\n",
    "Q1 = data['col1'].quantile(0.25)\n",
    "Q3 = data['col1'].quantile(0.75)\n",
    "# calculate the interquartile range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "# set the lower and upper bounds for outlier detection\n",
    "lower_bound = Q1 - (1.5 * IQR)\n",
    "upper_bound = Q3 + (1.5 * IQR)\n",
    "# identify outliers using the bounds\n",
    "outliers = (data['col1'] < lower_bound) | (data['col1'] > upper_bound)\n",
    "# set outliers to NA\n",
    "data_no_outliers = data[~outliers]\n",
    "# remove rows with NA\n",
    "data_no_outliers.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGxeHk9dGclE"
   },
   "source": [
    "# 2.5.3 | Outlier via Winsorizing\n",
    "Begrenzung min/max auf Grenze 5% und 95% Werte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JqqNVCceGjhA"
   },
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "# Begrenzung der Gültigkeit auf 5% - 95%, Anzahl bleibt erhalten, Werte <5% bzw. >95% werden auf Unter-/Obergrenze gesetzt\n",
    "data[num_col] = winsorize(data[num_col].values, limits=[0.05, 0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYucNU0sfuPf"
   },
   "source": [
    "# 2.5.4 | Outlier via LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pKF96SYf-oK"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "lof = LocalOutlierFactor(n_neighbors=5) # Ausreisser, wenn er sich stark von seinen Nachbarn unterscheidet\n",
    "outliers = lof.fit_predict(pd.DataFrame(target))\n",
    "# outliers = lof.fit_predict(data['colname'])\n",
    "num_outliers = len(outliers[outliers == -1])\n",
    "print(\"Anzahl der Ausreißer:\", num_outliers)\n",
    "\n",
    "# set outliers to NA\n",
    "data_no_outliers = data[~outliers]\n",
    "# remove rows with NA\n",
    "data_no_outliers.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKxDlyAvmxhb"
   },
   "source": [
    "# 2.6 | Codierung & Skalierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwWu-ylt2mLM"
   },
   "source": [
    "# 2.6.1 | Ordinal Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pkg7Z2eobWvt"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "data[cat_col] = OrdinalEncoder().fit_transform(data[cat_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLp2PSRdM0Jf"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "cat_seq = [['low', 'medium', 'high'],['red', 'green', 'blue']]  # Beispiel mit 2 Sequenzen\n",
    "data[cat_col] = OrdinalEncoder(categories=cat_seq).fit_transform(data[cat_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E1bbFmd6SDhd"
   },
   "outputs": [],
   "source": [
    "data.col.replace(['yes', 'no'], [1, 0], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6328kpIY2q47"
   },
   "source": [
    "# 2.6.2 | Nominal Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fMNfVXd-5iH4"
   },
   "outputs": [],
   "source": [
    "nom_col = ['Sex','Embarked']\n",
    "data = pd.concat([data, pd.get_dummies(data, columns=nom_col, prefix_sep='_')], axis='columns')\n",
    "data.drop(columns=nom_col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5QerEVKiu-7"
   },
   "outputs": [],
   "source": [
    "nom_col = ['Sex','Embarked']\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "data = pd.concat([data, pd.DataFrame(ohe.fit_transform(data[nom_col]), columns=ohe.get_feature_names_out())], axis=1)\n",
    "data.drop(columns=nom_col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ByCmV6BmA_2z"
   },
   "outputs": [],
   "source": [
    "# ab sklearn 1.3.2 (dev), aktuell Colab 1.2.2\n",
    "# data leakage - ggf. Encoding nach Trennung train/test oder k-fold target encoding - Umsetzung in sklearn ?\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "data_encoded = TargetEncoder().fit_transform(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--Tf9riW28O1"
   },
   "source": [
    "# 2.6.4 | LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSSWhrK6HXs6"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "target = LabelEncoder().fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zofMML31BiZJ"
   },
   "outputs": [],
   "source": [
    "target.replace(['yes', 'no'], [1, 0], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxQbtMihmxee"
   },
   "source": [
    "# 2.6.5 | Normalisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eRgI17panycs"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "data[num_col] = MinMaxScaler().fit_transform(data[num_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5Sowy6g5Q6T"
   },
   "source": [
    "# 2.6.6 | Standardisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FLRfyGjU5XmB"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data[num_col] = StandardScaler().fit_transform(data[num_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3H9yAzBGgbnT"
   },
   "source": [
    "# 2.6.7 | RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v386WK9-gfwS"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "data[num_col] = RobustScaler ().fit_transform(data[num_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xb0Sb7iFQoqG"
   },
   "source": [
    "# 2.7 | Dimensionen reduzieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0RSPY-FQurE"
   },
   "source": [
    "# 2.7.1 | Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uLrFIkGoR7Rn"
   },
   "outputs": [],
   "source": [
    "# - supervised\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda_np = lda.fit_transform(data, target)\n",
    "\n",
    "# Cube um lda erweitern\n",
    "col_name = [(\"LDA\" + str(i+1)) for i in range(lda_np.shape[1])]\n",
    "lda_df = pd.DataFrame(lda_np, columns=col_name)\n",
    "cube = pd.concat([cube, lda_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Jbq28mtlqqH"
   },
   "outputs": [],
   "source": [
    "feature_weights = lda.coef_\n",
    "df_feature_weights = pd.DataFrame(feature_weights,columns=columns, index=['class1', 'class2', ...])\n",
    "df_feature_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GM-lQLGjnEzD"
   },
   "outputs": [],
   "source": [
    "df_dfunction = pd.DataFrame(enumerate(explained_variance_ratios), columns=['Discr.-Function', 'expl. Variance'])\n",
    "df_dfunction['Discr.-Function'] += 1\n",
    "df_dfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wknLpaJXo5dP"
   },
   "outputs": [],
   "source": [
    "sum(explained_variance_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k57x57QoQ0b9"
   },
   "source": [
    "# 2.7.2 | Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nzcOe7m2RWVH"
   },
   "outputs": [],
   "source": [
    "# - unsupervised\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "pca = PCA()\n",
    "pca_np = pca.fit_transform(scale(data))\n",
    "\n",
    "# Cube um pca erweitern\n",
    "col_name = [(\"PCA\" + str(i+1)) for i in range(pca_np.shape[1])]\n",
    "pca_df = pd.DataFrame(pca_np, columns=col_name)\n",
    "cube = pd.concat([cube, pca_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9b5Wn1AZrODn"
   },
   "outputs": [],
   "source": [
    "feature_weights = pca.components_.T\n",
    "df_feature_weights = pd.DataFrame(feature_weights, columns=col_name, index=data.columns)\n",
    "df_feature_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_AeKidfCrPUH"
   },
   "outputs": [],
   "source": [
    "df_pcfunction = pd.DataFrame(enumerate(pca.explained_variance_ratio_), columns=['PCA', 'Variance'])\n",
    "df_pcfunction['PCA'] += 1\n",
    "df_pcfunction['cum. Variance'] = df_pcfunction['Variance'].cumsum()\n",
    "df_pcfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TeTfKyOvrTXX"
   },
   "outputs": [],
   "source": [
    "sum(explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YhUSf0sQtZdY"
   },
   "outputs": [],
   "source": [
    "# --- shorty\n",
    "from yellowbrick.features import pca_decomposition\n",
    "visualizer = pca_decomposition(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W78HInRYQBU3"
   },
   "source": [
    "# 2.8 | Imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_Ruv7SV6P2J"
   },
   "source": [
    "# 2.8.1 | Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38__mPeN6UFV"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "data_resampled, target_resampled = ros.fit_resample(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6kBna1q6gML"
   },
   "source": [
    "# 2.8.2 | Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1d8NrR436lRl"
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "data_resampled, target_resampled = rus.fit_resample(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jEtrqjqs60jw"
   },
   "source": [
    "# 2.8.3 | Klassen gewichten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYnFpbpF6IyB"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(target_train), target_train)\n",
    "model.fit(data_train, data_train, class_weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ou9Hb4SI7Jx4"
   },
   "source": [
    "# 2.8.4 | SMOTE\n",
    "(Synthetic Minority Over-sampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4oPwK8OF6IsP"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "data_resampled, target_resampled = smote.fit_resample(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUpWqmeT7lo4"
   },
   "source": [
    "# 2.8.5 | ADASYN\n",
    "(Adaptive Synthetic Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BXmy5kan6Il3"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "ada = ADASYN()\n",
    "data_resampled, target_resampled = ada.fit_resample(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzmfIwalmjGV"
   },
   "source": [
    "# 2.9 | Pipeline erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mozhj2wAQNH-"
   },
   "outputs": [],
   "source": [
    "data['col3'] = data['col1'] + data['col2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4iUn7DmlT3AS"
   },
   "source": [
    "# 2.10 Zeilen löschen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRy_r7JXT6JW"
   },
   "outputs": [],
   "source": [
    "data.drop('Zeileninhalt', axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jXm2B6KgUSOa"
   },
   "outputs": [],
   "source": [
    "# Datensätze mit Wert zwischne 1 und 10 löschen\n",
    "data_new = data[~(data['col'] > 1) & (data['col'] < 10)].drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIVwPn6B6K7-"
   },
   "source": [
    "# 3 | Modeling\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_odFYG4a9Qp"
   },
   "source": [
    "# 3.1 | Data-Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIePfoXQFrXa"
   },
   "source": [
    "# 3.1.1 | Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6arH63tP6P6Y"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size=0.3, random_state=42, stratify=target)\n",
    "data_train.shape, data_test.shape, target_train.shape, target_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpILK6DIRVtC"
   },
   "source": [
    "# 3.1.2 | Train-Val-Test-Split\n",
    "\n",
    "[train-val-test](https://towardsdatascience.com/how-to-split-data-into-three-sets-train-validation-and-test-and-why-e50d22d3e54c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-UMQ0H_RNJc"
   },
   "outputs": [],
   "source": [
    "from fast_ml.model_development import train_valid_test_split\n",
    "data_train, target_train, data_valid, target_valid, data_test, target_test = train_valid_test_split(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BELDsiDrF4bJ"
   },
   "source": [
    "# 3.2 | Special Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtRmYjroF-8v"
   },
   "source": [
    "# 3.2.1 | Time-Series-Slices (np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ywrOEX7VGDz3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sliding_window_dataset(raw_data, window_size, forecast_horizon):\n",
    "    dataset = []\n",
    "    targets = []\n",
    "\n",
    "    for i in range(len(raw_data) - window_size - forecast_horizon + 1):\n",
    "        window_slice = raw_data[i:i+window_size, :]\n",
    "        dataset.append(window_slice)\n",
    "        target_slice = raw_data[i+window_size:i+window_size+forecast_horizon, :]\n",
    "        targets.append(target_slice)\n",
    "\n",
    "    return np.array(dataset), np.array(targets)\n",
    "\n",
    "def expanding_window_dataset(raw_data, window_size, forecast_horizon):\n",
    "    dataset = []\n",
    "    targets = []\n",
    "\n",
    "    for i in range(window_size, len(raw_data) - forecast_horizon + 1):\n",
    "        window_slice = raw_data[:i, :]\n",
    "        dataset.append(window_slice)\n",
    "        target_slice = raw_data[i:i+forecast_horizon, :]\n",
    "        targets.append(target_slice)\n",
    "\n",
    "    return np.array(dataset), np.array(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90G_4lEdGJlq"
   },
   "outputs": [],
   "source": [
    "raw_data = np.array([[1, 2], [2, 4], [3, 6], [4, 8], [5, 10], [6, 12], [7, 14], [8, 16], [9, 18], [10, 20]])\n",
    "window_size = 3\n",
    "forecast_horizon = 2\n",
    "\n",
    "sliding_dataset, sliding_targets = sliding_window_dataset(raw_data, window_size, forecast_horizon)\n",
    "expanding_dataset, expanding_targets = expanding_window_dataset(raw_data, window_size, forecast_horizon)\n",
    "\n",
    "print(\"Sliding Dataset shape:\", sliding_dataset.shape)\n",
    "print(\"Sliding Targets shape:\", sliding_targets.shape)\n",
    "print(\"Expanding Dataset shape:\", expanding_dataset.shape)\n",
    "print(\"Expanding Targets shape:\", expanding_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wz6thZu0K9cL"
   },
   "source": [
    "# 3.2.2 | Time-Series-Slices (DataFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MosULd2XLEaO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def sliding_window_dataset(raw_data, window_size, forecast_horizon):\n",
    "    dataset = []\n",
    "    targets = []\n",
    "\n",
    "    for i in range(len(raw_data) - window_size - forecast_horizon + 1):\n",
    "        window_slice = raw_data.iloc[i:i+window_size]\n",
    "        dataset.append(window_slice)\n",
    "        target_slice = raw_data.iloc[i+window_size:i+window_size+forecast_horizon]\n",
    "        targets.append(target_slice)\n",
    "\n",
    "    return np.array(dataset), np.array(targets)\n",
    "\n",
    "def expanding_window_dataset(raw_data, window_size, forecast_horizon):\n",
    "    dataset = []\n",
    "    targets = []\n",
    "\n",
    "    for i in range(window_size, len(raw_data) - forecast_horizon + 1):\n",
    "        window_slice = raw_data.iloc[:i]\n",
    "        dataset.append(window_slice)\n",
    "        target_slice = raw_data.iloc[i:i+forecast_horizon]\n",
    "        targets.append(target_slice)\n",
    "\n",
    "    return np.array(dataset), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7_OY1LBLN6y"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12], [13, 14, 15]])\n",
    "df = pd.DataFrame(data, columns=['Feature1', 'Feature2', 'Feature3'])\n",
    "\n",
    "window_size = 2\n",
    "forecast_horizon = 1\n",
    "\n",
    "sliding_dataset, sliding_targets = sliding_window_dataset(df, window_size, forecast_horizon)\n",
    "expanding_dataset, expanding_targets = expanding_window_dataset(df, window_size, forecast_horizon)\n",
    "\n",
    "print(\"Sliding Dataset shape:\", sliding_dataset.shape)\n",
    "print(\"Sliding Targets shape:\", sliding_targets.shape)\n",
    "print(\"Expanding Dataset shape:\", expanding_dataset.shape)\n",
    "print(\"Expanding Targets shape:\", expanding_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFK6dO2op8G1"
   },
   "source": [
    "# 3.3 | Modelle Klassifizierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_LAqkEeXX2oW"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = estimator()\n",
    "model.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTUOuQFA9DI7"
   },
   "source": [
    "# 3.4 | Modelle Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RKnLRTRFYvlO"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "model = estimator()\n",
    "model.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MWnMsws39Jnj"
   },
   "source": [
    "# 3.5 | Modelle MultiLayerPerceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDWm1BFBMk9p"
   },
   "source": [
    "# 3.5.1 | Modelle MultiLayerPerceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DIi5U3T7YlDX"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "model = estimator()\n",
    "model.fit(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tykoiQUMMogB"
   },
   "source": [
    "# 3.5.2 | Loss-Entwicklung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MyQsnz3oMt89"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "title_ = 'Loss-Entwicklung'\n",
    "px.line(y=model.loss_curve_, title=title_, labels={'x':'Epochen', 'y':'Loss-Wert'}, width=800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAtLbfsK9xeb"
   },
   "source": [
    "# 3.6 | Modelle Association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uoj6HbAKZlXj"
   },
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "model = estimator()\n",
    "model.fit(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsvUd9UD9cGm"
   },
   "source": [
    "# 3.6 | Modelle Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TthilqlnZHvP"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "model = estimator()\n",
    "model.fit(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZedUYT69nWX"
   },
   "source": [
    "# 3.7 | Modelle Anomaly/Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYx2kz-WaAyX"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.lof import LOF\n",
    "\n",
    "model = estimator()\n",
    "model.fit(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlfOBn9IU87B"
   },
   "source": [
    "# 3.8 | Modelle Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RRTCepTuHfb"
   },
   "source": [
    "# 3.8.1 | Stacking Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AQW144NJkz5A"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cjUSzxkYwU5d"
   },
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "    ('knn', KNeighborsClassifier()),\n",
    "    ('svc', make_pipeline(StandardScaler(), LinearSVC(random_state=42)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LZF01XpquoBc"
   },
   "outputs": [],
   "source": [
    "model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "model.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9LQmEwy5t87Z"
   },
   "source": [
    "# 3.8.2 | Stacking Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3FMPGZbyO-9"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV\n",
    "from sklearn.ensemble import StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5PFIZh7P0WDH"
   },
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('rf', RandomForestRegressor(n_estimators=50, max_features=5, max_depth=20, min_samples_leaf=5, random_state=42)),\n",
    "    ('knn', KNeighborsRegressor(4)),\n",
    "    ('lreg', LinearRegression())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LYhz71VM1CLU"
   },
   "outputs": [],
   "source": [
    "model = StackingRegressor(estimators=estimators, final_estimator=RidgeCV())\n",
    "model.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vui1C8VRHJiw"
   },
   "source": [
    "# 4 | Evaluate\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVK3e-xjmEK4"
   },
   "source": [
    "# 4.1 | Modellgüte Klassifikation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_X1h11Z4-L43"
   },
   "source": [
    "# 4.1.1 | Prognose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uKJ280jYuXCK"
   },
   "outputs": [],
   "source": [
    "target_train_pred = model.predict(data_train)\n",
    "target_test_pred = model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fZA5fIKfO_NF"
   },
   "outputs": [],
   "source": [
    "# Prognose 2 neue Datensätze an das Modell übergeben\n",
    "# new_data = { 'feat1': [1, 2], 'feat2': [0, 1], 'feat4': [33, 80], 'feat5': [0, 0], 'feat6': [0, 0] }\n",
    "# new = pd.DataFrame(new_data)\n",
    "# model.predict(new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByHLP73j-Q0U"
   },
   "source": [
    "# 4.1.2 | Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWJ_qMGxKuHL"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc_train = accuracy_score(target_train, target_train_pred) * 100\n",
    "print (f\"Modell: {model} -- Train -- Accuracy: {acc_train:5.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3wMnO6nX-i4M"
   },
   "outputs": [],
   "source": [
    "acc_test = accuracy_score(target_test, target_test_pred) * 100\n",
    "print (f\"Modell: {model} -- Test -- Accuracy: {acc_test:5.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMnXiLepB4Go"
   },
   "source": [
    "# 4.1.3 | Precision, Recall, F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7-hooB9tB_Ov"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "precision = precision_score(target_test, target_test_pred)\n",
    "recall = recall_score(target_test, target_test_pred)\n",
    "f1 = f1_score(target_test, target_test_pred)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rScRRxwZNel"
   },
   "source": [
    "# 4.1.4 | Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Us6geMl9ZNwZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "conf_matrix = confusion_matrix(target_test, target_test_pred)\n",
    "display_labels_=['No','Yes']\n",
    "disp = ConfusionMatrixDisplay(conf_matrix, display_labels=display_labels_)\n",
    "disp.plot(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jyjZkRYJ-gut"
   },
   "outputs": [],
   "source": [
    "print(classification_report(target_test, target_test_pred, target_names=display_labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3srqXSJStqeO"
   },
   "source": [
    "# 4.1.5 | Cohen's Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzc_a9pVtsJs"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "target_pred = model.predict(data_train)\n",
    "cks_train = cohen_kappa_score(target_train, target_pred)\n",
    "print (f\"Modell: {model} -- Train -- Cohen's Kappa: {cks_train:5.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "roViD-HFDpyD"
   },
   "source": [
    "# 4.1.6 | ROC/AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IC1AKellA0gC"
   },
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ROCAUC\n",
    "classes_ = ['class1','class2']\n",
    "visualizer = ROCAUC(model, classes=classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GbpmMbr-A24v"
   },
   "outputs": [],
   "source": [
    "visualizer.fit(data_train, target_train)\n",
    "visualizer.score(data_test, target_test)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XxJLMHEmi1Nc"
   },
   "outputs": [],
   "source": [
    "from yellowbrick.classifier.rocauc import roc_auc\n",
    "roc_auc(model, X_train=data_train, y_train=target_train, X_test=data_test, y_test=target_test, classes=['No', 'Yes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Y0RlwfSitXv"
   },
   "source": [
    "# 4.1.7 | Discrimination Threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Css11DkitX2"
   },
   "outputs": [],
   "source": [
    "from yellowbrick.classifier.threshold import discrimination_threshold\n",
    "discrimination_threshold(model, data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XSYPoUVC77hF"
   },
   "outputs": [],
   "source": [
    "threshold = 0.45\n",
    "new_target_pred = (model.predict_proba(data_test)[:,1]>= threshold).astype(int)\n",
    "conf_matrix = confusion_matrix(target_test, new_target_pred)\n",
    "disp = ConfusionMatrixDisplay(conf_matrix, display_labels=['No','Yes'])\n",
    "disp.plot(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjyhHWhUhRWg"
   },
   "source": [
    "# 4.1.8 | Class Prediction Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rH-23pQ6hWTk"
   },
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import class_prediction_error\n",
    "classes = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "class_prediction_error(model,data_train, target_train, data_test, target_test, classes=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxGdp4WQDA-l"
   },
   "source": [
    "# 4.1.9 | TPR & FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLDHkcpVDJhH"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(target_test, target_test_pred).ravel()\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(\"True Positive Rate (TPR):\", tpr)\n",
    "print(\"False Positive Rate (FPR):\", fpr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbgOaOgwTK9A"
   },
   "source": [
    "# 4.2. | Modellgüte Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnMzM7VV_DbK"
   },
   "source": [
    "# 4.2.1 | Prognose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-5sdTtFDyOtY"
   },
   "outputs": [],
   "source": [
    "target_train_pred = model.predict(data_train)\n",
    "target_test_pred = model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JKzYs-wfPdJn"
   },
   "outputs": [],
   "source": [
    "# Prognose 2 neue Datensätze an das Modell übergeben\n",
    "# new_data = { 'feat1': [1, 2], 'feat2': [0, 1], 'feat4': [33, 80], 'feat5': [0, 0], 'feat6': [0, 0] }\n",
    "# new = pd.DataFrame(new_data)\n",
    "# model.predict(new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPC5NXQZ_HQq"
   },
   "source": [
    "# 4.2.2 | Bestimmtheitsmass - r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LqNWtD0qurC5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_train = r2_score(target_train, target_train_pred)\n",
    "print(f'Modell: {model}\\n -- Train -- Bestimmtheitsmass: {r2_train:5.2f}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFnCK4ve_N_A"
   },
   "outputs": [],
   "source": [
    "r2_test = r2_score(target_test, target_test_pred)\n",
    "print(f'Modell: {model}\\n -- Test -- Bestimmtheitsmass: {r2_test:5.2f}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4jAxagOuzpj"
   },
   "source": [
    "# 4.2.3 | Mean Absolut Error - MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l3JeOMj4uzK2"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(target_test, target_test_pred)\n",
    "print(f'Modell: {model} -- Test -- Mean Absolute Error: {mae:5.2f}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9hy5tg2Tixh"
   },
   "source": [
    "# 4.2.4 | Regressionskoeffizienten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UGd2eoDoThyh"
   },
   "outputs": [],
   "source": [
    "print('Intercept/Ursprung: %10.2f' %float(model.intercept_))\n",
    "anzahl = len(model.coef_)\n",
    "print(f'Slope/Steigung der {anzahl} Merkmale: \\n ', model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzkHUd4qf8d-"
   },
   "source": [
    "# 4.2.5 | Residuals Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Za0KeZiPgDUD"
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import residuals_plot\n",
    "viz = residuals_plot(model, data_train, target_train, data_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9vVYHHVN7km"
   },
   "source": [
    "# 4.2.6 | Prediction Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJdw26OiNufa"
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import prediction_error\n",
    "visualizer = prediction_error(model, data_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fOaDozwgLkM"
   },
   "source": [
    "# 4.2.7 | f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bIF0uMFKgLkc"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_regression\n",
    "fscores, pvalues = f_regression(data_test, target_test)\n",
    "for i in range(len(fscores)):\n",
    "    print(f\"Feature {i+1}: {data.columns[i]:10s} score = {fscores[i]:>12,.2f}, p-value = {pvalues[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5GvA406pkz9K"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "px.bar(x=fscores, y=data.columns, width=600, height=600).update_yaxes(categoryorder=\"total ascending\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7_MQO7KQRVQ"
   },
   "source": [
    "# 4.3 | Modellgüte Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oOx4177QYrq"
   },
   "source": [
    "# 4.3.1 | Silhouette Koeffizient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0rFE0sWQsUR"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "silhouette_coef = silhouette_score(data, model.labels_)\n",
    "print(\"Silhouette-Koeffizient:\", silhouette_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1hPQSCmtUOVh"
   },
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "visualizer = SilhouetteVisualizer(model_kmeans, colors='yellowbrick')\n",
    "visualizer.fit(data)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MkoNLpKDZGyG"
   },
   "outputs": [],
   "source": [
    "# visualizer.silhouette_samples_\n",
    "# visualizer.silhouette_score_\n",
    "# visualizer.y_tick_pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ad7YRohQU0NH"
   },
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import intercluster_distance\n",
    "visualizer = intercluster_distance(model_kmeans, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gos_FfUdvQK8"
   },
   "source": [
    "# 4.3.2 |  Calinski-Harabasz-Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_lPw8gfbvWkL"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import calinski_harabasz_score\n",
    "ch_score = calinski_harabasz_score(data, model.labels_)\n",
    "print(\"Calinski-Harabasz Index:\", ch_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsl04_3DvrRF"
   },
   "source": [
    "# 4.3.3 | Rand Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "75fzwarzvucZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "rand_score = adjusted_rand_score(target, model.labels_)\n",
    "print(\"Rand Index:\", rand_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyaguIG1RChQ"
   },
   "source": [
    "# 4.3.4 | Homogenität & Vollständigkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iNjq6nr9RJLv"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import homogeneity_score, completeness_score\n",
    "homogeneity = homogeneity_score(target, target_pred)\n",
    "completeness = completeness_score(target, target_pred)\n",
    "print(\"Homogenität:\", homogeneity)\n",
    "print(\"Vollständigkeit:\", completeness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrIr_j7EAUkS"
   },
   "source": [
    "# 4.4 | Residuenanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwfgI9VfAzNF"
   },
   "source": [
    "# 4.4.1a | Aufbau Analysewürfel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_93Ho-hNFUot"
   },
   "outputs": [],
   "source": [
    "# Übernahme der Testdaten\n",
    "cube = data_test.copy()\n",
    "cube.reset_index(inplace=True)\n",
    "\n",
    "# Übernahem Target real & predict\n",
    "cube['real'] = pd.DataFrame(target_test.values, columns=['real'])\n",
    "cube['predict'] = pd.DataFrame(target_test_pred, columns=['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Shfbn82ChtUb"
   },
   "outputs": [],
   "source": [
    "# Erstellung 2D Features über Dimensionsreduktion PCA - unsupervised\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_np = pca.fit_transform(scale(data_test))\n",
    "pca_df = pd.DataFrame(pca_np)\n",
    "\n",
    "# Cube um pca erweitern\n",
    "col_name = [(\"PCA\" + str(i+1)) for i in range(pca_np.shape[1])]\n",
    "pca_df = pd.DataFrame(pca_np, columns=col_name)\n",
    "cube = pd.concat([cube, pca_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwBCm2cgQr1z"
   },
   "source": [
    "# 4.4.1b | Aufbau Analysewürfe (proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-K8DpxusQqzN"
   },
   "outputs": [],
   "source": [
    "# Übernahme der Testdaten\n",
    "cube = data_test.copy()\n",
    "cube.reset_index(inplace=True)\n",
    "\n",
    "# Übernahem Target real & predict\n",
    "cube['real_no'] = pd.DataFrame(target_test[:,0], columns=['real_no'])\n",
    "cube['real_yes'] = pd.DataFrame(target_test[:,1], columns=['real_yes'])\n",
    "cube['predict_no'] = pd.DataFrame(target_test_pred[:,0], columns=['predict_no'])\n",
    "cube['predict_yes'] = pd.DataFrame(target_test_pred[:,1], columns=['predict_yes'])\n",
    "\n",
    "cube['real'] = cube['real_yes']\n",
    "cube['predict'] = round(cube['predict_yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WP9yvD9mhxls"
   },
   "outputs": [],
   "source": [
    "# Erstellung 2D Features über Dimensionsreduktion PCA - unsupervised\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_np = pca.fit_transform(scale(data_test))\n",
    "pca_df = pd.DataFrame(pca_np)\n",
    "\n",
    "# Cube um pca erweitern\n",
    "col_name = [(\"PCA\" + str(i+1)) for i in range(pca_np.shape[1])]\n",
    "pca_df = pd.DataFrame(pca_np, columns=col_name)\n",
    "cube = pd.concat([cube, pca_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWybk1ZjzV_4"
   },
   "source": [
    "# 4.4.2 | Visualisierung real vs predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UBwm3httxcHy"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.subplots as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "camte9DPxcHz"
   },
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "title_ = 'Boxplot real vs predict'\n",
    "px.box(cube[['real', 'predict']], title=title_, width=600, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFCd0OFHIqoh"
   },
   "outputs": [],
   "source": [
    "# Histogramm\n",
    "title_ = 'Histogramm real vs predict'\n",
    "fig = px.histogram(cube, x=['real', 'predict'], text_auto=\".2s\", nbins=2, title=title_)\n",
    "fig.update_layout(barmode='group',bargap=0.1, width=800, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aQULsB4wJlam"
   },
   "outputs": [],
   "source": [
    "# 2 x Scatterplots\n",
    "\n",
    "# cube['real_cat'] = cube['real'].astype(str)\n",
    "# cube['predict_cat'] = cube['predict'].astype(str)\n",
    "\n",
    "# Farbzuteilung für Kategoriewerte\n",
    "color_mapping = {'0': 'red', '1': 'blue'}\n",
    "\n",
    "img1 = px.scatter(cube, x='PCA1', y='PCA2', color='real', color_discrete_map=color_mapping, width=600, height=600)\n",
    "img2 = px.scatter(cube, x='PCA1', y='PCA2', color='predict', color_discrete_map=color_mapping, width=600, height=600)\n",
    "\n",
    "fig = sp.make_subplots(rows=1, cols=2, subplot_titles=('Scatterplot real', 'Scatterplot predict'))\n",
    "\n",
    "for trace in img1.data:\n",
    "    fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "for trace in img2.data:\n",
    "    fig.add_trace(trace, row=1, col=2)\n",
    "\n",
    "# Layout anpassen\n",
    "title_ = 'Streupunktdiagramm ...'\n",
    "fig.update_layout(width=1000, height=500, title_text=title_)\n",
    "\n",
    "# Plot anzeigen\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IHy1KUixZ68k"
   },
   "outputs": [],
   "source": [
    "# Matching Mehr-Klassenzuordnung (nicht binär)\n",
    "import plotly.express as px\n",
    "\n",
    "title_ = 'Streupunktdiagramm Klassen real vs predict'\n",
    "# Berechnen der Anzahl von x=y\n",
    "cube['count'] = cube.groupby(['real', 'predict'])['real'].transform('count')\n",
    "\n",
    "# Erstellen des Scatterplots mit Größe der Punkte abhängig von der Anzahl von x=y\n",
    "fig = px.scatter(cube, x='real', y='predict', size='count', width=700, height=700)\n",
    "\n",
    "# Anpassen der Größe der Punkte im Scatterplot\n",
    "fig.update_traces(marker=dict(sizemode='area', sizeref=0.7))\n",
    "\n",
    "# Anzeigen des Scatterplots\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s0xfx1VlcwvP"
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import residuals_plot\n",
    "viz = residuals_plot(model, data_train, target_train, data_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTPXvvTEN3wo"
   },
   "source": [
    "# 4.4.3 | Fehlerhafte Vorhersagen (cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X4vg5RqrKsBD"
   },
   "outputs": [],
   "source": [
    "# real <> predict\n",
    "cube[cube.real != cube.predict].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nTzTVTmoMiFb"
   },
   "outputs": [],
   "source": [
    "cube[cube.real != cube.predict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nO6BASDim1px"
   },
   "source": [
    "# 4.4.4 | Fehlerhafte Vorhersagen (num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qQoxqAim-ha"
   },
   "outputs": [],
   "source": [
    "cube['abs_Abw%'] = abs((cube['real'] - cube['predict']) / cube['real'] *100)\n",
    "%precision 3\n",
    "cube.head(10).style.format(\"{:,.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ki7yPFIpsW0V"
   },
   "outputs": [],
   "source": [
    "# Histogramm\n",
    "title_ = 'Histogramm absolute Abweichung'\n",
    "fig = px.histogram(cube, x=['abs_Abw%'], text_auto=\".2s\", nbins=20, title=title_)\n",
    "fig.update_layout(barmode='group',bargap=0.2, width=800, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aD_ZLrmCcCH1"
   },
   "source": [
    "# 4.4.5 | Einzelne Vorhersage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqJTctDbiW8v"
   },
   "outputs": [],
   "source": [
    "# 2 neue Datensätze werden zur Prognose an das Modell übergeben: Rose & Jack\n",
    "new_data = { 'pclass': [1, 3], 'sex': [1, 0], 'age': [22, 23], 'sibsp': [0, 0], 'parch': [0, 0] }\n",
    "new = pd.DataFrame(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cTBd4YdBkBNI"
   },
   "outputs": [],
   "source": [
    "# Vorhersage erstellen Rose & Jack\n",
    "model.predict(new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOR0ZUCZNY1n"
   },
   "source": [
    "# 4.4.6 | Residuals Plot (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kCc-uDkONY1o"
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import residuals_plot\n",
    "viz = residuals_plot(model, data_train, target_train, data_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gM0Eo8sHSq4"
   },
   "source": [
    "# 4.5 | Feature Importance/Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KOQBtKPAKd7"
   },
   "source": [
    "# 4.5.1 | Feature Importance Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C9SmQUdHHJ3U"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "px.bar(x=model.feature_importances_, y=data.columns, text_auto=\".2s\", title='Feature Importance', width=800, height=500).update_yaxes(categoryorder=\"total ascending\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPuU_muv5ZJH"
   },
   "source": [
    "# 4.5.2 | Feature Importance Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4fJAaIY5f9L"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_regression\n",
    "fscores, pvalues = f_regression(data_test, target_test)\n",
    "for i in range(len(fscores)):\n",
    "    print(f\"Feature {i+1}: {data.columns[i]:10s} score = {fscores[i]:>12,.2f}, p-value = {pvalues[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJK9dPXUklqD"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "px.bar(x=fscores, y=data.columns, text_auto=\".2s\", title='Feature Importance', width=600, height=600).update_yaxes(categoryorder=\"total ascending\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SB6rrynwAEXC"
   },
   "source": [
    "# 4.5.3 | Feature Importance yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSbeCv9lc9Nb"
   },
   "outputs": [],
   "source": [
    "from yellowbrick.model_selection import feature_importances\n",
    "feature_importances(model, data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crJV4e7XAZuY"
   },
   "source": [
    "# 4.5.4 | Select Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4uAs39IYdEly"
   },
   "outputs": [],
   "source": [
    "# Die Wahl zwischen chi2 (kategorisch) und f_regression (numerisch) hängt von der Art der Zielvariable ab\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression\n",
    "k_best = SelectKBest(score_func=chi2, k=3)     # k = top 3 features\n",
    "X_new = k_best.fit_transform(data, target)\n",
    "feature_indices = k_best.get_support(indices=True)\n",
    "feature_names = data.columns[feature_indices]\n",
    "print(\"Selected features:\", feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRHKZUTmDPNl"
   },
   "source": [
    "# 4.5.5 | Recursive Feature Elimination\n",
    "sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "owC51rE0DUo4"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(estimator=model, n_features_to_select=1)\n",
    "rfe.fit(X, y)\n",
    "feature_ranking = rfe.ranking_\n",
    "feature_names = data.columns\n",
    "for rank, name in sorted(zip(feature_ranking, feature_names)):\n",
    "    print(f'Feature \"{name}\" has rank {rank}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wq0QT-5oba5h"
   },
   "source": [
    "# 4.5.6 | Recursive Feature Elimination\n",
    "yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bSIRMV9arKor"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from yellowbrick.model_selection import rfecv\n",
    "cv = StratifiedKFold(5)\n",
    "visualizer = rfecv(model, X=data, y=target, cv=cv, scoring='f1_weighted') # Regression: scoring='r2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0xkr9kb72vs"
   },
   "outputs": [],
   "source": [
    "visualizer.support_, visualizer.ranking_, visualizer.cv_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqZjP2h8La8_"
   },
   "source": [
    "# 4.5.7 | Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tdn9Y26ELe1m"
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "lda_data = lda.fit_transform(data_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPqUz9wYjtwy"
   },
   "source": [
    "# 4.6 | Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNC0vwoSopqh"
   },
   "source": [
    "# 4.6.1 | Cross Validation sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tsfE1Acx_USp"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NR0axyeN02El"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "cv_results = cross_validate(model, data_train, target_train,\n",
    "                            scoring='r2', cv=cv, return_train_score=True, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_bvZR5Ss5PQd"
   },
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Adev45SG1yY1"
   },
   "outputs": [],
   "source": [
    "train_result = cv_results['test_score'].mean()\n",
    "val_result = cv_results['train_score'].mean()\n",
    "print(f\"Train {train_result:.2f} -- Validation {val_result:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IiyRDxHRovU4"
   },
   "source": [
    "# 4.6.2 | Coss Validation yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L7FyijB1liUh"
   },
   "outputs": [],
   "source": [
    "from yellowbrick.model_selection import cv_scores\n",
    "visualizer = cv_scores(model, data, target, cv=cv, scoring='r2')  # Classification: scoring='f1_weighted'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdEl7qXGdxCJ"
   },
   "source": [
    "# 4.7 | HyperparameterTuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuwBv3pxiOxu"
   },
   "source": [
    "# 4.7.1 | GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9lyvyuMLELX1"
   },
   "outputs": [],
   "source": [
    "param_grid = {}\n",
    "param_grid['param1'] = [10, 50, (10,10,10)]\n",
    "param_grid['param2'] = ['identity','logistic','relu']\n",
    "param_grid['param3'] =['lbfgs','sgd','adam']\n",
    "param_grid['param4'] = ['constant','invscaling','adaptive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hJiAUdz3sBj"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "gs_cv = GridSearchCV(model, param_grid, cv=2, scoring=['accuracy'],return_train_score= True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-fLPKRr32CZ"
   },
   "outputs": [],
   "source": [
    "gs_cv.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JjTc54VvipYg"
   },
   "outputs": [],
   "source": [
    "gs_cv.best_estimator_\n",
    "gs_cv.best_params_\n",
    "gs_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sj2zW47TipYg"
   },
   "outputs": [],
   "source": [
    "gs_cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q-obvd-cXUiN"
   },
   "outputs": [],
   "source": [
    "l_mta = list()\n",
    "l_params = list()\n",
    "\n",
    "all_results = gs_cv.cv_results_\n",
    "for mta, params in zip(all_results[\"mean_test_accuracy\"], all_results['params']):\n",
    "  l_mta.append(mta)\n",
    "  l_params.append(params)\n",
    "\n",
    "results = pd.DataFrame(columns=['MTA', 'Parameter'])\n",
    "results.MTA = l_mta\n",
    "results.Parameter = l_params\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPGuinjwhyn4"
   },
   "source": [
    "# 4.7.2 | RandomizedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qINj_DXnN6FM"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-XRi1lTbtOGo"
   },
   "outputs": [],
   "source": [
    "param_grid = {}\n",
    "param_grid['param1'] = np.arange(10, 100, 10)\n",
    "param_grid['param2'] = np.arange(10, 30, 5)\n",
    "param_grid['param3'] = np.arange(2, 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HZ0RQEhe_q1_"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rs_cv = RandomizedSearchCV(estimator = model, param_distributions=param_grid, n_iter=15, cv=5, scoring=\"r2\", verbose=2, random_state=42)\n",
    "rs_cv.fit(data_test,target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3GVgEc6E4_ut"
   },
   "outputs": [],
   "source": [
    "rs_cv.best_estimator_\n",
    "rs_cv.best_params_\n",
    "rs_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4TyF2oVtaXQ"
   },
   "outputs": [],
   "source": [
    "rs_cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w2x0_twB_q2E"
   },
   "outputs": [],
   "source": [
    "l_mts = list()\n",
    "l_params = list()\n",
    "\n",
    "all_results = rs_cv.cv_results_\n",
    "for mts, params in zip(all_results[\"mean_test_score\"], all_results['params']):\n",
    "  l_mts.append(mts)\n",
    "  l_params.append(params)\n",
    "\n",
    "results = pd.DataFrame(columns=['MTS', 'Parameter'])\n",
    "results.MTS = l_mts\n",
    "results.Parameter = l_params\n",
    "results.sort_values(by=['MTS'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fa0PJDJGd7cC"
   },
   "source": [
    "# 4.8 | Modellinterpretation allgemein\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBfhu22D4YkJ"
   },
   "source": [
    "# 4.8.1 | Tree visual - dtreeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dIpofCO14dUX"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "  import dtreeviz\n",
    "except:\n",
    "  !pip install -q dtreeviz\n",
    "  import dtreeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KmhvTpEl6QWd"
   },
   "outputs": [],
   "source": [
    "viz_model = dtreeviz.model(model,\n",
    "                           data, target,\n",
    "                           target_name=\"target\",\n",
    "                           class_names=display_labels_,\n",
    "                           feature_names=data.columns\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R7YqtuKi_sd-"
   },
   "outputs": [],
   "source": [
    "viz_model.view(scale=1.0, fontname='Monospace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vC4sbcNU7ZZK"
   },
   "outputs": [],
   "source": [
    "viz_model.view(scale=1.2, orientation=\"LR\", fontname='Monospace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PiLLG0TbTF6j"
   },
   "outputs": [],
   "source": [
    "# local Explanation\n",
    "one = data_test.iloc[13]\n",
    "viz_model.view(x=one, fontname='Monospace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6o9QKaDxQono"
   },
   "outputs": [],
   "source": [
    "# local Explanation\n",
    "viz_model.view(x=one, show_just_path=True, fontname='Monospace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9lUbn54sDEY"
   },
   "outputs": [],
   "source": [
    "tree_img = viz_model.view(scale=0.8, fontname='Monospace')\n",
    "tree_img.save('tree.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZ11SJtBM-JN"
   },
   "source": [
    "# 4.8.2 | Tree visual - graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VFy9b9Ys4Mkk"
   },
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from sklearn import tree\n",
    "# DOT data\n",
    "dot_data = tree.export_graphviz(model, out_file=None,\n",
    "                                feature_names=data.columns,\n",
    "                                class_names=display_labels_,\n",
    "                                filled=True)\n",
    "\n",
    "# Draw graph\n",
    "graph = graphviz.Source(dot_data, format=\"png\")\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOQrubvhcxsS"
   },
   "source": [
    "# 4.9 | Verschiedenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2oV7kF4bL60"
   },
   "source": [
    "# 4.9.1 | Discrimination Threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VqiZs5RY6Kwr"
   },
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import DiscriminationThreshold\n",
    "# Instantiate the classification model and visualizer\n",
    "visualizer = DiscriminationThreshold(model, random_state=42)\n",
    "visualizer.fit(data_test, target_test, random_state=42)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-eoLHiM3iLVb"
   },
   "outputs": [],
   "source": [
    "# --- Quick Version mit Fehler\n",
    "# from yellowbrick.classifier.threshold import discrimination_threshold\n",
    "# discrimination_threshold(model, data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZtdVxdzk8MD5"
   },
   "outputs": [],
   "source": [
    "threshold = 0.45\n",
    "new_target_pred = (model.predict_proba(data_test)[:,1]>= threshold).astype(int)\n",
    "conf_matrix = confusion_matrix(target_test, new_target_pred)\n",
    "disp = ConfusionMatrixDisplay(conf_matrix, display_labels=['No','Yes'])\n",
    "disp.plot(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jl88Aol8P_4y"
   },
   "source": [
    "# 4.9.2 | Round Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "svEIcqiLc0FF"
   },
   "outputs": [],
   "source": [
    "rounded_predictions = np.argmax(predictions, axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ueQbQvMmlnlk"
   },
   "source": [
    "# 4.9.3 | Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X2d7mBtwlrZh"
   },
   "outputs": [],
   "source": [
    "from yellowbrick.model_selection import validation_curve\n",
    "viz = validation_curve(model, data, target, param_name=\"max_depth\", param_range=np.arange(1, 11), cv=10, scoring=\"r2\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5cK7wHPmHw4"
   },
   "source": [
    "# 4.9.4 | Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HBcCbQwMmNAB"
   },
   "outputs": [],
   "source": [
    "from yellowbrick.model_selection import learning_curve\n",
    "learning_curve(model, data, target, scoring='r2')   #  Clustering: scoring='adjusted_rand_score', Classification: scoring='f1_weighted', Regression: scoring='r2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rU30R-4OroKD"
   },
   "source": [
    "# 5 | Deploy\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bk529CVFWjPT"
   },
   "source": [
    "# 5.1 | Save Model (joblib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2xAjcaa8gYt5"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(model, '/content/cv-model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXCO0b__WpKJ"
   },
   "source": [
    "# 5.2 | Load Model (Joblib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oaBL0_5PWgbp"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "model_geladen = joblib.load('/content/cv-model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69VvRy1uxf2A"
   },
   "source": [
    "# 5.3 | Save Model (pmml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y9JcQw-6jS90"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "    from sklearn2pmml import sklearn2pmml, make_pmml_pipeline\n",
    "    from pypmml import Model\n",
    "except:\n",
    "    !pip install -q sklearn2pmml\n",
    "    !pip install -q pypmml\n",
    "    from sklearn2pmml import sklearn2pmml, make_pmml_pipeline\n",
    "    from pypmml import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__C8jQNEmZ-5"
   },
   "outputs": [],
   "source": [
    "pmml_pipe = make_pmml_pipeline(model, data.columns.values, target.name)\n",
    "sklearn2pmml(pmml_pipe, \"trained_model.pmml\", with_repr = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVQmKA89o5ZO"
   },
   "source": [
    "# 5.4 | Load Model (pmml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mn2tjt9zjahH"
   },
   "outputs": [],
   "source": [
    "from pypmml import Model\n",
    "model_load = Model.load('/content/trained_model.pmml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPRdwXrVCFHi"
   },
   "source": [
    "# 5.5 | Save Model (pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IjVjF4L2CKX2"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open(model_file_path, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uv6HBl7wCWXy"
   },
   "source": [
    "# 5.6 | Load Model (pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84y5hQbqCO2k"
   },
   "outputs": [],
   "source": [
    "model = pickle.load(open(model_file_path, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ql-xNcE-v8rs"
   },
   "source": [
    "# 6 | Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qB_hxC4Wv_xr"
   },
   "source": [
    "# 6.1 | DataFrames in Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-C4HkgFwOc1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.array(data)\n",
    "target = np.array(target)\n",
    "data = np.asarray(data).astype(np.float32)\n",
    "data.shape, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUv1mXBZwQt2"
   },
   "source": [
    "# 6.2 | Import Layer & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jzvk2_6-wbaC"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7nEeomhwc9e"
   },
   "source": [
    "# 6.3 | Aufbau Neuronales Netz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3_bpjzIxHZx"
   },
   "source": [
    "# 6.3.1 | Klassifizierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oorazDshxV94"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=[15, ]))             # Input Layer 15 Parameter\n",
    "model.add(Dense(45, activation=\"relu\"))\n",
    "model.add(Dense(45, activation=\"relu\"))\n",
    "model.add(Dense(2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3oHUuXm-x-az"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HsPXDImcyAGv"
   },
   "outputs": [],
   "source": [
    "model.fit(data_train, target_train, validation_split=0.3, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQE4u_lF5SQL"
   },
   "outputs": [],
   "source": [
    "print(model.history.params)\n",
    "print(model.history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TC9WcYZpQz8W"
   },
   "outputs": [],
   "source": [
    "target_train_pred = model.predict(data_train)\n",
    "target_test_pred = model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7PFE0qXgUYTs"
   },
   "outputs": [],
   "source": [
    "# --- Vorverarbeitung: Umwandlung Array mit Wahrscheinlichkeiten in Array mit 0/1\n",
    "import numpy as np\n",
    "def probabilities_to_binary(matrix):\n",
    "    max_indices = tf.keras.backend.argmax(matrix, axis=1)\n",
    "    binary_matrix = tf.keras.backend.one_hot(max_indices, matrix.shape[1])\n",
    "    return binary_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ql2R6XdWR9H8"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "target_train_pred_ = probabilities_to_binary(target_train_pred)\n",
    "acc_train = accuracy_score(target_train, target_train_pred_) * 100\n",
    "print (f\"Modell: {model} -- Train -- Accuracy: {acc_train:5.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HtmDpTsSR9H8"
   },
   "outputs": [],
   "source": [
    "target_test_pred_ = probabilities_to_binary(target_test_pred)\n",
    "acc_test = accuracy_score(target_test, target_test_pred_) * 100\n",
    "print (f\"Modell: {model} -- Test -- Accuracy: {acc_test:5.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3gf87taxMXo"
   },
   "source": [
    "# 6.3.2. | Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OyHV6n5gwl1g"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=13, input_dim=13, kernel_initializer='normal', activation='relu'))          # 13 Input Paramter\n",
    "model.add(Dense(units=600, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(units=600, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(units=600, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(units=600, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(units=600, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(units=8, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6mFTx9bPyRdT"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='mse', optimizer=opt, metrics=[tf.keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZ79T4E5yTj_"
   },
   "outputs": [],
   "source": [
    "model.fit(data_train, target_train, epochs=100, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGKe_AtjPzds"
   },
   "outputs": [],
   "source": [
    "print(model.history.params)\n",
    "print(model.history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SA4OEJas5crr"
   },
   "outputs": [],
   "source": [
    "target_train_pred = model.predict(data_train)\n",
    "target_test_pred = model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s2hgzu-p51eI"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_train = r2_score(target_train, target_train_pred)\n",
    "print(f'Modell: {model}\\n -- Train -- Bestimmtheitsmass: {r2_train:5.2f}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3z-Oz_G51eR"
   },
   "outputs": [],
   "source": [
    "r2_test = r2_score(target_test, target_test_pred)\n",
    "print(f'Modell: {model}\\n -- Test -- Bestimmtheitsmass: {r2_test:5.2f}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dv07CKFt51eS"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(target_test, target_test_pred)\n",
    "print(f'Modell: {model} -- Test -- Mean Absolute Error: {mae:5.2f}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dDrqmn2wnId"
   },
   "source": [
    "# 6.4 | Anzeigen Netzwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wqadfeCy_iF"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMOEFPu9P6xy"
   },
   "source": [
    "# 6.5 | Loss-Entwicklung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RjxkcUKDM1Rj"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "title_ = 'Loss-Entwicklung'\n",
    "px.line(y=model.history.history['loss'], title=title_, labels={'x':'Epochen', 'y':'Loss-Wert'}, width=800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzAXsRpJZxcB"
   },
   "source": [
    "# 6.6 | Zufallszahl initialisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rbp7xU15Z3Qr"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMq84oLiaI2BMbxp+aNLKtY",
   "collapsed_sections": [
    "cO3WizxxG80I",
    "Nhp-ceAziZO3",
    "PFk4S8G2t6sG",
    "4GY9_DS0iMGo",
    "NQ68SwBd9OyW",
    "FxcV51QtilCo",
    "1cWkGhG-i03_",
    "6JXf146TzXdh",
    "WbBQSUPnBPFD",
    "D9VeDtH-BV-W",
    "q0kZq6iTtvsp",
    "uhfT9PdGf4GX",
    "aodL9sOpGyM0",
    "jcfPgWTMONq4",
    "65K6EoL7HHly",
    "a-3PtOrx0hhY",
    "OUEEfjP3mp9A",
    "nTTTfWUgmqFU",
    "_r6jjOnY0liS",
    "nxQuQ_Yr0qf-",
    "z-s4qTMq1InQ",
    "QwuxgST8Pmfc",
    "CJ8hRzn6aIP5",
    "3_TAfRLCZheu",
    "pCb4mTGfmpzo",
    "GgKcm9_HTmsk",
    "RICK4opXTrdO",
    "cb9C30MjTwx3",
    "FPdhVA_6mxpc",
    "TzYXteA2FISC",
    "R9sK8P7RLPyU",
    "aGxeHk9dGclE",
    "jYucNU0sfuPf",
    "nKxDlyAvmxhb",
    "GwWu-ylt2mLM",
    "6328kpIY2q47",
    "--Tf9riW28O1",
    "qxQbtMihmxee",
    "S5Sowy6g5Q6T",
    "3H9yAzBGgbnT",
    "xb0Sb7iFQoqG",
    "y0RSPY-FQurE",
    "k57x57QoQ0b9",
    "W78HInRYQBU3",
    "R_Ruv7SV6P2J",
    "r6kBna1q6gML",
    "jEtrqjqs60jw",
    "ou9Hb4SI7Jx4",
    "BUpWqmeT7lo4",
    "UzmfIwalmjGV",
    "4iUn7DmlT3AS",
    "FIVwPn6B6K7-",
    "z_odFYG4a9Qp",
    "JIePfoXQFrXa",
    "SpILK6DIRVtC",
    "BELDsiDrF4bJ",
    "gtRmYjroF-8v",
    "wz6thZu0K9cL",
    "TFK6dO2op8G1",
    "iTUOuQFA9DI7",
    "MWnMsws39Jnj",
    "TDWm1BFBMk9p",
    "tykoiQUMMogB",
    "ZAtLbfsK9xeb",
    "PsvUd9UD9cGm",
    "FZedUYT69nWX",
    "dlfOBn9IU87B",
    "_RRTCepTuHfb",
    "9LQmEwy5t87Z",
    "vui1C8VRHJiw",
    "IVK3e-xjmEK4",
    "_X1h11Z4-L43",
    "ByHLP73j-Q0U",
    "aMnXiLepB4Go",
    "-rScRRxwZNel",
    "3srqXSJStqeO",
    "roViD-HFDpyD",
    "5Y0RlwfSitXv",
    "ZjyhHWhUhRWg",
    "mxGdp4WQDA-l",
    "NbgOaOgwTK9A",
    "BnMzM7VV_DbK",
    "KPC5NXQZ_HQq",
    "n4jAxagOuzpj",
    "e9hy5tg2Tixh",
    "VzkHUd4qf8d-",
    "l9vVYHHVN7km",
    "0fOaDozwgLkM",
    "D7_MQO7KQRVQ",
    "1oOx4177QYrq",
    "gos_FfUdvQK8",
    "lsl04_3DvrRF",
    "fyaguIG1RChQ",
    "hrIr_j7EAUkS",
    "rwfgI9VfAzNF",
    "HwBCm2cgQr1z",
    "WWybk1ZjzV_4",
    "KTPXvvTEN3wo",
    "nO6BASDim1px",
    "aD_ZLrmCcCH1",
    "AOR0ZUCZNY1n",
    "-gM0Eo8sHSq4",
    "5KOQBtKPAKd7",
    "uPuU_muv5ZJH",
    "SB6rrynwAEXC",
    "crJV4e7XAZuY",
    "KRHKZUTmDPNl",
    "wq0QT-5oba5h",
    "EqZjP2h8La8_",
    "FPqUz9wYjtwy",
    "eNC0vwoSopqh",
    "IiyRDxHRovU4",
    "fdEl7qXGdxCJ",
    "LuwBv3pxiOxu",
    "GPGuinjwhyn4",
    "fa0PJDJGd7cC",
    "dBfhu22D4YkJ",
    "HZ11SJtBM-JN",
    "FOQrubvhcxsS",
    "c2oV7kF4bL60",
    "jl88Aol8P_4y",
    "ueQbQvMmlnlk",
    "h5cK7wHPmHw4",
    "rU30R-4OroKD",
    "bk529CVFWjPT",
    "jXCO0b__WpKJ",
    "69VvRy1uxf2A",
    "hVQmKA89o5ZO",
    "WPRdwXrVCFHi",
    "Uv6HBl7wCWXy",
    "Ql-xNcE-v8rs",
    "qB_hxC4Wv_xr",
    "DUv1mXBZwQt2",
    "T7nEeomhwc9e",
    "c3_bpjzIxHZx",
    "I3gf87taxMXo",
    "8dDrqmn2wnId",
    "zMOEFPu9P6xy",
    "qzAXsRpJZxcB"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
